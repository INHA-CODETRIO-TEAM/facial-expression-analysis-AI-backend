{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOWE0bq0hnkA6FghWfLQ6tx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"051SuEO0myoP"},"outputs":[],"source":["import os\n","from PIL import Image\n","import tensorflow as tf\n","import numpy as np\n","import cv2\n","\n","import torchvision.transforms as transforms\n","from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","from functools import partial\n","from typing import Any, Callable, List, Optional, Type, Union\n","import torch\n","import torch.nn as nn\n","from torch import Tensor\n","\n","def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n","\n","\n","def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","class BasicBlock(nn.Module):\n","    def __init__(\n","        self,\n","        inplanes: int,\n","        planes: int,\n","        stride: int = 1,\n","        downsample: Optional[nn.Module] = None,\n","        groups: int = 1,\n","        #dilation: int = 1,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None\n","    ) -> None:\n","        super(BasicBlock, self).__init__()\n","\n","        # Normalization Layer\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.LeakyReLU(0.1)\n","        #self.relu=nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        # downsampling이 필요한 경우 downsample layer를 block에 인자로 넣어주어야함\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity  # residual connection\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(\n","        self,\n","        block: BasicBlock,\n","        layers: List[int],\n","        num_classes: int = 1000,\n","        zero_init_residual: bool = False,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None\n","    ) -> None:\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer  # batch norm layer\n","\n","        self.inplanes = 64  # input shape\n","        #self.dilation = 1  # dilation fixed\n","        self.groups = 1  # groups fixed\n","\n","        # input block\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = norm_layer(self.inplanes)\n","        #self.relu =nn.LeakyReLU(0.1)\n","        self.relu=nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        # residual blocks\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, num_classes)\n","\n","\n","        # weight initialization\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n","\n","    def _make_layer(self, block: BasicBlock, planes: int, blocks: int,\n","                    stride: int = 1) -> nn.Sequential:\n","        norm_layer = self._norm_layer\n","        downsample = None\n","\n","        # downsampling 필요할경우 downsample layer 생성\n","        if stride != 1 or self.inplanes != planes:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes, stride),\n","                norm_layer(planes),\n","            )\n","\n","        layers = []\n","        #layers.append(block(self.inplanes, planes, stride, downsample, self.groups,self.dilation, norm_layer))\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            norm_layer))\n","        self.inplanes = planes\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        print(\"forward\")\n","        #print('input shape:', x.shape)\n","        x = self.conv1(x)\n","        #print('conv1 shape:', x.shape)\n","        x = self.bn1(x)\n","        #print('bn1 shape:', x.shape)\n","        x = self.relu(x)\n","        #print('relu shape:', x.shape)\n","        x = self.maxpool(x)\n","        #print('maxpool shape:', x.shape)\n","\n","        x = self.layer1(x)\n","        #print('layer1 shape:', x.shape)\n","        x = self.layer2(x)\n","        #print('layer2 shape:', x.shape)\n","        x = self.layer3(x)\n","        #print('layer3 shape:', x.shape)\n","        x = self.layer4(x)\n","        #print('layer4 shape:', x.shape)\n","\n","        x = self.avgpool(x)\n","        #print('avgpool shape:', x.shape)\n","        x = torch.flatten(x, 1)\n","        #print('flatten shape:', x.shape)\n","        x = self.fc(x)\n","        #print('fc shape:', x.shape)\n","\n","        return x\n","\n","# ResNet-50 모델 정의\n","model = ResNet(BasicBlock,[3,4,4,3],num_classes=5,zero_init_residual=True)\n","\n","# 미리 학습된 가중치 불러오기\n","checkpoint = torch.load('/content/drive/MyDrive/model_checkpoint_epoch1.pt')\n","\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.eval()\n","\n","\n","\n","def classify_faces(face_images):\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","\n","    predictions = []\n","    '''\n","    for face in face_images:\n","        input_tensor = transform(face).unsqueeze(0)  # 배치 차원 추가\n","        with torch.no_grad():\n","            output = ResNet(input_tensor)\n","        _, predicted_class = torch.max(output, 1)\n","        predictions.append(predicted_class.item())\n","    '''\n","\n","    input_tensor = transform(face_image).unsqueeze(0)  # Adding batch dimension\n","    with torch.no_grad():\n","        output = model(input_tensor)\n","    return output\n","\n","from flask import Flask, request, jsonify\n","import io\n","from PIL import Image\n","\n","app = Flask(__name__)\n","\n","@app.route('/')\n","def hello_world():\n","    return 'Hello, World!'\n","\n","@app.route('/detect_and_classify', methods=['POST'])\n","def detect_and_classify():\n","    # 클라이언트로부터 이미지 파일 받기\n","    image_file = request.files['image']\n","    image_bytes = image_file.read()\n","    image = Image.open(io.BytesIO(image_bytes))\n","\n","    # 얼굴 분류\n","    predictions = classify_faces(image)\n","\n","    # Softmax 함수를 사용하여 확률값으로 변환\n","    predictions = torch.softmax(predictions, dim=1)\n","    predictions = predictions.squeeze().tolist()\n","    #predictions= [\"{:.3f}\".format(value) for value in predictions]\n","    # 결과 반환\n","    #return jsonify(predictions.squeeze().tolist())\n","    return jsonify(predictions)\n","if __name__ == '__main__':\n","    app.run(debug=True)"]}]}