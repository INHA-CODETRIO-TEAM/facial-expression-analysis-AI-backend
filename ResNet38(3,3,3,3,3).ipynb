{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Q5QwK2Wd_gk7"},"outputs":[],"source":["import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","import random\n","import numpy as np\n","from torch.nn import Module\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","from functools import partial\n","from typing import Any, Callable, List, Optional, Type, Union\n","from torch import Tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_0XtdkbvtKe"},"outputs":[],"source":["class CustomTrainDataset1(Dataset,Module):\n","    def __init__(self, folder_path, index_array, transform=None):\n","        self.folder_path = folder_path\n","        self.image_files=[os.path.join(folder_path,file) for file in os.listdir(folder_path)]\n","        self.image_paths=random.sample(self.image_files,10000)\n","        #self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path)[:7000] if img.endswith('.jpg')]\n","        self.label = index_array\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        image_name = os.path.basename(image_path)  # 이미지 파일의 이름을 가져오기\n","        image = Image.open(image_path).convert('RGB')  # 이미지를 열고 RGB 형식으로 변환\n","        if self.transform:\n","            image = self.transform(image)\n","        return image,self.label\n","\n","# 이미지 전처리를 위한 변환기 설정\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # 이미지 크기 조절\n","    transforms.ToTensor(),           # 이미지를 텐서로 변환\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n","])\n","\n"]},{"cell_type":"code","source":["#라벨 정보\n","LABELS={'pleasure':0,\n","        'embarrased':1,\n","        'angry':2,\n","        'anxiety':3,\n","        'sad':4,\n","        'neutral':5}\n","\n","datasets=[]\n","\n","for label_name,label in LABELS.items():\n","  folder_path1=f'/content/drive/Othercomputers/내MacBookAir/valid{label_name}'\n","  # CustomDataset 객체 생성\n","  datasets.append(CustomTrainDataset1(folder_path1, label, transform=transform))"],"metadata":{"id":"g_Al9B6Y1jV7","colab":{"base_uri":"https://localhost:8080/","height":456},"executionInfo":{"status":"error","timestamp":1701870644582,"user_tz":-540,"elapsed":889,"user":{"displayName":"김성아","userId":"17267080986120858203"}},"outputId":"cc090a72-e72c-4c6d-cd03-c56b49ca00af"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-4fc575a91a3e>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mfolder_path1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'/content/drive/Othercomputers/내MacBookAir/valid{label_name}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# CustomDataset 객체 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCustomTrainDataset1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-4bcc6a61672d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, folder_path, index_array, transform)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path)[:7000] if img.endswith('.jpg')]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Othercomputers/내MacBookAir/validpleasure'"]}]},{"cell_type":"code","source":["# DataLoader를 사용하여 배치로 나누기\n","batch_size = 128"],"metadata":{"id":"qvK4HOKs2SL1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvLmtSA7UmYC"},"outputs":[],"source":["train_loader = DataLoader(torch.utils.data.ConcatDataset(datasets), batch_size=batch_size, shuffle=True,num_workers=8)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnQwaZzGvufW"},"outputs":[],"source":["class CustomTrainDataset2(Dataset,Module):\n","    def __init__(self, folder_path, index_array, transform=None):\n","        self.folder_path = folder_path\n","        image_files=[os.path.join(folder_path,file) for file in os.listdir(folder_path)]\n","        self.image_paths=random.sample(image_files,5000)\n","        self.label = index_array\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        image_name = os.path.basename(image_path)  # 이미지 파일의 이름을 가져오기\n","        image = Image.open(image_path).convert('RGB')  # 이미지를 열고 RGB 형식으로 변환\n","        if self.transform:\n","            image = self.transform(image)\n","        return image,self.label\n","\n","# 이미지 전처리를 위한 변환기 설정\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # 이미지 크기 조절\n","    transforms.ToTensor(),           # 이미지를 텐서로 변환\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ae14TWlBv3W_"},"outputs":[],"source":["class CustomValidDataset(Dataset,Module):\n","    def __init__(self, folder_path, index_array, transform=None):\n","        self.folder_path = folder_path\n","        image_files=[os.path.join(folder_path,file) for file in os.listdir(folder_path)]\n","        self.image_paths=random.sample(image_files,1000)\n","        #self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path)[:1000] if img.endswith('.jpg')]\n","        self.label = index_array\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        image_name = os.path.basename(image_path)  # 이미지 파일의 이름을 가져오기\n","        image = Image.open(image_path).convert('RGB')  # 이미지를 열고 RGB 형식으로 변환\n","        if self.transform:\n","            image = self.transform(image)\n","        return image,self.label\n","\n","# 이미지 전처리를 위한 변환기 설정\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # 이미지 크기 조절\n","    transforms.ToTensor(),           # 이미지를 텐서로 변환\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n","])"]},{"cell_type":"code","source":["#라벨 정보\n","LABELS={'기쁨':0,\n","        '당황':1,\n","        '분노':2,\n","        '불안':3,\n","        '슬픔':4,\n","        '중립':5}\n","\n","datasets=[]\n","\n","for label_name,label in LABELS.items():\n","  folder_path=f'/content/drive/Othercomputers/내MacBookAir/valid{label_name}'\n","  # CustomDataset 객체 생성\n","  datasets.append(CustomValidDataset(folder_path, label, transform=transform))"],"metadata":{"id":"YrElv7xCqA0h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_loader = DataLoader(torch.utils.data.ConcatDataset(datasets), batch_size=batch_size, shuffle=True,num_workers=8)"],"metadata":{"id":"OikKF3m6qdij"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaC4byRNv88T"},"outputs":[],"source":["import pickle\n","\n","def save_data_loader(dataloader, file_path):\n","    with open(file_path, 'wb') as file:\n","        pickle.dump(dataloader, file)\n","\n","def load_data_loader(file_path):\n","    with open(file_path, 'rb') as file:\n","        dataloader = pickle.load(file)\n","    return dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZoljU2Iv_ek"},"outputs":[],"source":["# DataLoader 객체를 파일에 저장\n","#save_data_loader(train_loader, '/content/drive/MyDrive/종설/train_Dataloader3.pkl')\n","#save_data_loader(valid_loader, '/content/drive/MyDrive/종설/valid_Dataloader3.pkl')\n","\n","# 파일에서 DataLoader 객체 불러오기\n","train_loader = load_data_loader('/content/drive/MyDrive/종설/train_Dataloader3.pkl')\n","valid_loader = load_data_loader('/content/drive/MyDrive/종설/valid_Dataloader.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZATV1Y7IwB2E"},"outputs":[],"source":["print(len(train_loader.dataset))\n","print(len(valid_loader.dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPPR16coaA7b"},"outputs":[],"source":["def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n","\n","\n","def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y34P9Hqs_X5u"},"outputs":[],"source":["class BasicBlock(nn.Module):\n","    def __init__(\n","        self,\n","        inplanes: int,\n","        planes: int,\n","        stride: int = 1,\n","        downsample: Optional[nn.Module] = None,\n","        groups: int = 1,\n","        #dilation: int = 1,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None\n","    ) -> None:\n","        super(BasicBlock, self).__init__()\n","\n","        # Normalization Layer\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.LeakyReLU(0.1)\n","        #self.relu=nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        # downsampling이 필요한 경우 downsample layer를 block에 인자로 넣어주어야함\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity  # residual connection\n","        out = self.relu(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c-iGA5hT_eSi"},"outputs":[],"source":["class ResNet(nn.Module):\n","    def __init__(\n","        self,\n","        block: BasicBlock,\n","        layers: List[int],\n","        num_classes: int = 1000,\n","        zero_init_residual: bool = False,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None\n","    ) -> None:\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer  # batch norm layer\n","\n","        self.inplanes = 64  # input shape\n","        #self.dilation = 1  # dilation fixed\n","        self.groups = 1  # groups fixed\n","\n","        # input block\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = nn.LeakyReLU(0.1)\n","        #self.relu=nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        # residual blocks\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.layer5 = self._make_layer(block, 1024, layers[4], stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        #self.fc = nn.Linear(512, num_classes)\n","        self.fc = nn.Linear(1024, num_classes)\n","\n","\n","        # weight initialization\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n","\n","    def _make_layer(self, block: BasicBlock, planes: int, blocks: int,\n","                    stride: int = 1) -> nn.Sequential:\n","        norm_layer = self._norm_layer\n","        downsample = None\n","\n","        # downsampling 필요할경우 downsample layer 생성\n","        if stride != 1 or self.inplanes != planes:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes, stride),\n","                norm_layer(planes),\n","            )\n","\n","        layers = []\n","        #layers.append(block(self.inplanes, planes, stride, downsample, self.groups,self.dilation, norm_layer))\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            norm_layer))\n","        self.inplanes = planes\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        print('input shape:', x.shape)\n","        x = self.conv1(x)\n","        print('conv1 shape:', x.shape)\n","        x = self.bn1(x)\n","        print('bn1 shape:', x.shape)\n","        x = self.relu(x)\n","        print('relu shape:', x.shape)\n","        x = self.maxpool(x)\n","        print('maxpool shape:', x.shape)\n","\n","        x = self.layer1(x)\n","        print('layer1 shape:', x.shape)\n","        x = self.layer2(x)\n","        print('layer2 shape:', x.shape)\n","        x = self.layer3(x)\n","        print('layer3 shape:', x.shape)\n","        x = self.layer4(x)\n","        print('layer4 shape:', x.shape)\n","        x = self.layer5(x)\n","        print('layer5 shape:', x.shape)\n","        x = self.avgpool(x)\n","        print('avgpool shape:', x.shape)\n","        x = torch.flatten(x, 1)\n","        print('flatten shape:', x.shape)\n","        x = self.fc(x)\n","        print('fc shape:', x.shape)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyXP5AlYqLAn"},"outputs":[],"source":["# ResNet-50 모델 정의\n","#model = ResNet(BasicBlock,[3,4,8,3],num_classes=6,zero_init_residual=True)\n","model = ResNet(BasicBlock,[3,4,4,4,3],num_classes=6,zero_init_residual=True)\n","# 손실 함수 및 옵티마이저 설정\n","criterion = CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vxS582N9s9fn"},"outputs":[],"source":["# 모델 학습\n","num_epochs = 20\n","# 에폭을 반복하면서 학습과 검증을 수행\n","for epoch in range(num_epochs):\n","    '''\n","    checkpoint = torch.load('/content/drive/MyDrive/Resnet(3,3,3,3,3)_checkpoint_epoch{}.pt'.format(epoch))\n","    # 모델과 옵티마이저의 상태 복원\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    '''\n","    i=0\n","    # 학습 단계\n","    for inputs, targets in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs,targets)\n","        loss.backward()\n","        optimizer.step()\n","        print(f'epoch: {epoch}, batch: {i}')\n","        i+=1\n","\n","    # 각 에폭 종료 후 검증 단계\n","    model.eval()  # 모델을 평가 모드로 전환\n","    val_loss = 0.0\n","    correct_predictions = 0\n","    total_samples = 0\n","\n","    with torch.no_grad():\n","        for val_inputs, val_targets in valid_loader:\n","            val_outputs = model(val_inputs)\n","            val_loss += criterion(val_outputs, val_targets).item()\n","\n","            # 정확도 계산\n","            _, predicted = torch.max(val_outputs, 1)\n","            correct_predictions += (predicted == val_targets).sum().item()\n","            total_samples += val_targets.size(0)\n","\n","    average_val_loss = val_loss / len(valid_loader)\n","    accuracy = (correct_predictions / total_samples) * 100\n","\n","    # 에폭 종료 후 출력\n","    print(f'Epoch [{epoch}/{num_epochs}], Accuracy: {accuracy:.2f}%')\n","\n","\n","    checkpoint = {\n","    'epoch': epoch,\n","    'model_state_dict': model.state_dict(),\n","    'optimizer_state_dict': optimizer.state_dict(),\n","    'accuracy':accuracy,\n","    }\n","\n","    # 저장 경로 설정\n","    #save_path = '/content/drive/MyDrive/Resnet(3,4,8,3)_checkpoint_epoch{}.pt'.format(epoch)\n","    save_path = '/content/drive/MyDrive/Resnet(3,4,4,4,3)_checkpoint_epoch{}.pt'.format(epoch)\n","    # 딕셔너리를 파일로 저장\n","    torch.save(checkpoint, save_path)\n","\n","\n","    model.train()  # 모델을 학습 모드로 전환\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fvtfRxPp0sCt"},"outputs":[],"source":["saved_epoch=0\n","checkpoint = torch.load('/content/drive/MyDrive/Resnet(3,4,4,4,3)_checkpoint_epoch{}.pt'.format(saved_epoch))\n","# 모델과 옵티마이저의 상태 복원\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","#epoch = checkpoint['epoch']\n","accuracy = checkpoint['accuracy']\n","print(accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHz9ti7K2zYU"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100","mount_file_id":"1nwXK2xannFwi83XB4SjMyRcboDHI2Cpe","authorship_tag":"ABX9TyPfQWHlCmxEmCb94Zo9aiTC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}